import tempfile
import traceback
from pathlib import Path

import gradio as gr

def save_tmp_audio(audio, cache_dir):
    with tempfile.NamedTemporaryFile(
        dir=cache_dir, delete=False, suffix=".wav"
    ) as temp_audio:
        temp_audio.write(audio)
    return temp_audio.name

def add_message(chatbot, history, mic, text):
    if not mic and not text:
        return chatbot, history, "Input is empty"

    if text:
        chatbot.append({"role": "user", "content": text})
        history.append({"role": "human", "content": text})
    elif mic and Path(mic).exists():
        chatbot.append({"role": "user", "content": {"path": mic}})
        history.append({"role": "human", "content": [{"type":"audio", "audio": mic}]})

    print(f"{history=}")
    return chatbot, history, None

def reset_state(system_prompt):
    return [], [{"role": "system", "content": system_prompt}]

def predict(chatbot, history, audio_model, token2wav, prompt_wav, cache_dir):
    try:
        history.append({"role": "assistant", "content": [{"type": "text", "text": "<tts_start>"}], "eot": False})
        tokens, text, audio = audio_model(history, max_new_tokens=4096, temperature=0.7, repetition_penalty=1.05, do_sample=True)
        print(f"predict {text=}")
        audio = token2wav(audio, prompt_wav)
        audio_path = save_tmp_audio(audio, cache_dir)
        chatbot.append({"role": "assistant", "content": {"path": audio_path}})
        history[-1]["content"].append({"type": "token", "token": tokens})
        history[-1]["eot"] = True
    except Exception:
        print(traceback.format_exc())
        gr.Warning(f"Some error happend, please try again.")
    return chatbot, history

def _launch_demo(args, audio_model, token2wav):
    with gr.Blocks(delete_cache=(86400, 86400)) as demo:
        gr.Markdown("""<center><font size=8>Step Audio 2 Demo</center>""")
        with gr.Row():
            system_prompt = gr.Textbox(
                label="System Prompt",
                value="ä½ çš„åå­—å«åšå°è·ƒï¼Œæ˜¯ç”±é˜¶è·ƒæ˜Ÿè¾°å…¬å¸è®­ç»ƒå‡ºæ¥çš„è¯­éŸ³å¤§æ¨¡å‹ã€‚\nä½ æƒ…æ„Ÿç»†è…»ï¼Œè§‚å¯Ÿèƒ½åŠ›å¼ºï¼Œæ“…é•¿åˆ†æç”¨æˆ·çš„å†…å®¹ï¼Œå¹¶ä½œå‡ºå–„è§£äººæ„çš„å›å¤ï¼Œè¯´è¯çš„è¿‡ç¨‹ä¸­æ—¶åˆ»æ³¨æ„ç”¨æˆ·çš„æ„Ÿå—ï¼Œå¯Œæœ‰åŒç†å¿ƒï¼Œæä¾›å¤šæ ·çš„æƒ…ç»ªä»·å€¼ã€‚\nä»Šå¤©æ˜¯2025å¹´8æœˆ29æ—¥ï¼Œæ˜ŸæœŸäº”\nè¯·ç”¨é»˜è®¤å¥³å£°ä¸ç”¨æˆ·äº¤æµã€‚",
                lines=2
            )
        chatbot = gr.Chatbot(
            elem_id="chatbot",
            #avatar_images=["assets/user.png", "assets/assistant.png"],
            min_height=800,
            type="messages",
        )
        history = gr.State([{"role": "system", "content": system_prompt.value}])
        mic = gr.Audio(type="filepath")
        text = gr.Textbox(placeholder="Enter message ...")

        with gr.Row():
            clean_btn = gr.Button("ğŸ§¹ Clear History (æ¸…é™¤å†å²)")
            regen_btn = gr.Button("ğŸ¤”ï¸ Regenerate (é‡è¯•)")
            submit_btn = gr.Button("ğŸš€ Submit")

        def on_submit(chatbot, history, mic, text):
            chatbot, history, error = add_message(
                chatbot, history, mic, text
            )
            if error:
                gr.Warning(error)  # æ˜¾ç¤ºè­¦å‘Šæ¶ˆæ¯
                return chatbot, history, None, None
            else:
                chatbot, history = predict(chatbot, history, audio_model, token2wav, args.prompt_wav, args.cache_dir)
                return chatbot, history, None, None

        submit_btn.click(
            fn=on_submit,
            inputs=[chatbot, history, mic, text],
            outputs=[chatbot, history, mic, text],
            concurrency_limit=4,
            concurrency_id="gpu_queue",
        )

        clean_btn.click(
            fn=reset_state,
            inputs=[system_prompt],
            outputs=[chatbot, history],
            #show_progress=True,
        )

        def regenerate(chatbot, history):
            while chatbot and chatbot[-1]["role"] == "assistant":
                chatbot.pop()
            while history and history[-1]["role"] == "assistant":
                print(f"discard {history[-1]}")
                history.pop()
            return predict(chatbot, history, audio_model, token2wav, args.prompt_wav, args.cache_dir)

        regen_btn.click(
            regenerate,
            [chatbot, history],
            [chatbot, history],
            #show_progress=True,
            concurrency_id="gpu_queue",
        )

    demo.queue().launch(
        server_port=args.server_port,
        server_name=args.server_name,
    )


if __name__ == "__main__":
    import os
    from argparse import ArgumentParser

    from stepaudio2 import StepAudio2
    from token2wav import Token2wav

    parser = ArgumentParser()
    parser.add_argument("--model-path", type=str, default='Step-Audio-2-mini', help="Model path.")
    parser.add_argument(
        "--server-port", type=int, default=7860, help="Demo server port."
    )
    parser.add_argument(
        "--server-name", type=str, default="0.0.0.0", help="Demo server name."
    )
    parser.add_argument(
        "--prompt-wav", type=str, default="assets/default_female.wav", help="Prompt wave for the assistant."
    )
    parser.add_argument(
        "--cache-dir", type=str, default="/tmp/stepaudio2", help="Cache directory."
    )
    args = parser.parse_args()
    os.environ["GRADIO_TEMP_DIR"] = args.cache_dir

    audio_model = StepAudio2(args.model_path)
    token2wav = Token2wav(f"{args.model_path}/token2wav")
    _launch_demo(args, audio_model, token2wav)
